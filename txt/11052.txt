Data Is the New What? Popular Metaphors &
Professional Ethics in Emerging Data Culture
Luke Stark and Anna Lauren Hoffmann
05.02.19
Peer-Reviewed By: Anonymous and Dr. Brian Beaton
Clusters: Data, Infrastructure
Article DOI: 10.22148/16.036
Journal ISSN: 2371-4549
Cite: Luke Stark and Anna Lauren Hoffmann, “Data Is the New What? Popular
Metaphors & Professional Ethics in Emerging Data Culture,” Journal of Cultural
Analytics. May 2, 2019.

A growing list of high-profile controversies involving the social impacts of artificial intelligence systems (AI), digital data collection and algorithmic analysis have forced difficult conversations around the ethics of data-intensive digital technologies and so-called “big data” research.12 These incidents are directly
relevant to newly coalescing cultures of “data science,” an emergent field which
seeks both to interpret and capitalize on the creation, collection, and processing
of knowledge through large collections of digital data, often in conjunction with
particular techniques like machine learning (ML).1 The long list of recent public controversies, as Brian Beaton observes, lays bare data science’s extant lack of
direction regarding professional ethics or values.2
1 Brian Beaton, Amelia Acker, Lauren Di Monte, Shivrang Setlur, Tonia Sutherland, and Sarah
E Tracy, “Debating Data Science,” Radical History Review 2017, no. 127 (March 2, 2017): 133-48.
doi:10.1215/01636545-3690918.
2 Brian Beaton, “How to Respond to Data Science: Early Data Criticism by Lionel Trilling,” Information & Culture: a Journal of History 51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303.

1

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

Various groups have ventured into this conceptual gap to advance principles or
guidelines for doing ethical data science. In 2017, for example, digital organization Data for Democracy (D4D)—in partnership with media conglomerate
Bloomberg and open source platform BrightHive—announced an effort to
crowdsource a code of ethics for data scientists, seeking to “define values and
priorities for overall ethical behavior, in order to guide a data scientist in being
a thoughtful, responsible agent of change.”3 This recent focus on developing
ethical codes for data science (alongside related areas such as AI/ML) suggests
the field seeks to address its social impacts through discourses and processes
of professional consolidation.4 Yet such efforts raise further questions. What
kind of work counts as “data science” in the first place? What are its aims and
historical precursors? And what, if any, baseline ethical commitments bind
disparately situated researchers, analysts, and (of course) professional data
scientists?
As data science seeks to constitute itself as a professional field, these questions
will continue to lurk in the background of efforts to articulate and codify data
science’s ethical commitments. In this paper, we examine one dimension of this
conceptual terrain: the relevance and resonance of extant codes of professional
and research ethics in—and beyond—domains related to computing, information science, and data analytics. The paper proceeds in four parts. In the first,
we draw on work in the history and sociology of professional ethics to establish
the (often fraught) relationship between ethical codes, professionalization, and
moral responsibility, with a focus on ethics codes in domains conventionally allied with data science such as computing and information science. Second, we
expand the domain of potentially relevant professional analogues by reviewing
and drawing inspiration from many of the popular metaphors for “data”—and
by extension, the work of data scientists—proliferating in both popular and academic settings.
In the third and fourth sections, we employ discourse analysis to assess two sets
of professional ethics codes: one set rooted in conventionally allied domains like
computing; the other derived from those professions evoked by the metaphors
associated with data and data science. Through this discursive analysis, we develop a number of insights regarding the challenges and opportunities of developing a code of ethics for data science, and by extension the ambivalent role of
3 “Code
of
Ethics,”
Data
for
Democracy,
accessed
June
2,
2018,
http://datafordemocracy.org/projects/ethics.html.
4 For an analysis of ethics statements in the AI context, see Daniel Greene, Anna Lauren Hoffmann,
and Luke Stark (forthcoming), ”Better, nicer, clearer, fairer: A critical assessment of the movement
for ethical artificial intelligence and machine learning,” 52nd Hawaii International Conference on
Systems Science.

2

Cultural Analytics

Data Is the New What?

data science as a profession within a broader tapestry of “data cultures.”5 With
multiple metaphors for what “big data” is and can do, and multiple potentially
relevant ethics codes scattered across different domains, data ethics is a field in
flux. Collectively, these conversations represent an effort to better grapple with
the consequences of the language we use for understanding and working with
data—“big” or otherwise—today, and how our discourses around data cultures
shape their material, cultural, and political impact.

Ethics Codes As/And Professional Cultures
Codes of ethics are longstanding mechanisms through which groups of experts
have sought to define themselves and their priorities as “professionals,” or recognized members of particular professions.6 High-status professions such as doctors, lawyers and engineers pioneered professional ethics codes as early as the
eighteenth century. Today, many other groups of experts—from foresters to firefighters to astrologers—have enacted these codes as signals, sometimes merely aspirational, of their professional status. Ongoing historical and sociological work
in this area has shown such codes can and have served a range of valuable functions, from educating professionals and instilling positive group norms to setting
benchmarks against which unethical behavior may be censured.910 Most important for present purposes, a profession’s ethical code offers insight into how it
collectively understands and seeks to modulate the distribution of obligations
between individual practitioners, other individuals or stakeholders, and society
more broadly.7
In his survey of the history of professional ethics codes, Andrew Abbot demonstrates the ubiquity of such codes as a key element of industrial state/social formation, representing perhaps “the most concrete cultural form in which professions
acknowledge their societal obligations.”8 These codes do not arise in theoretical
or conceptual vacuums. As Jacob Metcalf writes of research ethics, they represent “hard-won responses to major disruptions, especially medical and behavioral research scandals.”9 In addition, ethics codes are enforced most often when
5 Kath Albury et al., “Data Cultures of Mobile Dating and Hook-Up Apps: Emerging Issues for
Critical Social Science Research,” Big Data & Society 4, no. 2 (July 3, 2017): 205395171772095-11,
135, doi:10.1177/2053951717720950.
6 Harold L Wilensky, “The Professionalization of Everyone?,” American Journal of Sociology 70, no.
2 (September 1964): 137-58.
7 Abbott, “Professional Ethics,” 856.
8 Abbott, “Professional Ethics.”
9 Jacob Metcalf, “Ethics Codes: History, Context, and Challenges,” Council for Big Data, Ethics,
and Society, November 9, 2014.

3

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

ethical infractions or controversies are highly visible. As Abbot notes, “general
public service obligations are extremely important as claims but extremely vague
as rules.”10 Mark Frankel likewise notes a relationship between ”professions’ pursuit of autonomy,11 and the public’s demand for accountability.”12 In view of this
tension between visibility and vagueness, ethics codes often elide granular attention to professional activities, relying instead on informal everyday rules over
which individual practitioners have some (albeit limited) control.
Fundamental to these debates is the question of whether a professional ethics
code should be a fine-grained “how-to” manual or a set of broad principles to be
inculcated into an individual. These questions are particularly evident in the history of engineering codes and engineering ethics.13 For engineers, there remains
a tension in the inherent definition of a profession as a group of experts explicitly set to serve the general public, and a profession’s own interests as a particular
group.14 Extant conversations surrounding codes of ethics for computing mirror
these disagreements.15 As Metcalf observes, the current surge of practitioner and
public interest in ethics of data science was paralleled by a flurry of work in the
early 1990s by major international professional organizations—including the Association of Computing Machinery (ACM) and the Institute of Electrical and
Electronics Engineers (IEEE)—to draft and implement ethics codes.16 Metcalf
suggests ethics codes are often reactive, instituted in response to crises of professional confidence.17 Further, Effy Oz’s assessment of ethics codes from four professional associations involving computing,18 including the ACM, argued the lack
of prioritization around moral obligations to various groups, common to professional ethics codes more generally, is especially pronounced in professional computing codes.19 As Frankel warns, ethics codes that fail to engage with broader
social values and expectations risk becoming mere “political tools” for signaling
moral virtue to society at large.
10 Metcalf,

“Ethics Codes: History, Context, and Challenges,” 863.
“Professional Codes: Why, How, and with What Impact?”
12 Frankel, “Professional Codes: Why, How, and with What Impact?,” 109.
13 Heinz C. Luegenbiehl, “Codes of Ethics and the Moral Education of Engineers,” Business Professional Ethics Journal 2, no. 4 (1983): 41-61.
14 Michael Davis, “Thinking Like an Engineer: the Place of a Code of Ethics in the Practice of a
Profession,” Philosophy & Public Affairs 20, no. 2 (1991): 150-67.
15 Effy Oz, “Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major
Codes,” Journal of Business Ethics 12, no. 9 (September 1993): 709-26.
16 Metcalf, “Ethics Codes: History, Context, and Challenges.”
17 Metcalf, “Ethics Codes: History, Context, and Challenges.”
18 Oz,“Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major
Codes.”
19 Don Gotterbarn and James H Moor, “Virtual Decisions: Video Game Ethics, Just Consequentialism, and Ethics on the Fly,” SIGCAS Computers and Society 39, no. 3 (December 2009): 27-42.
11 Frankel,

4

Cultural Analytics

Data Is the New What?

Data & Data Science Metaphors
If professional codes of ethics are often “hard-won responses to major disruptions,” we should attend to the nature of the “disruption” in question. Doing so
points towards previously underappreciated or overlooked ethical domains—in
this case, domains which help us better come to terms with the rise of the data
scientist and an epistemological shift in how we produce, understand, and act
on knowledge about the world.20 Here, we identify additional domains of ethical
consideration relevant to data ethics by turning to the metaphors we use to talk
about data itself.
The metaphors we deploy to make sense of new tools and technologies serve
the dual purpose of highlighting the novel by reference to the familiar, while
also obscuring or abstracting away from some features of a given technology or
practice21 —as Teun A. van Dijk describes,22 metaphors “are powerful means to
make abstract mental models more concrete.”23 In this way, metaphors—Rowan
Wilken notes24 —are never innocent; they “always influence and shape the meanings that are generated by, and the meanings which accumulate around, a given
metaphor.”25 For example, as Dawn Nafus describes in the domain of data visualization,26 the idea that data wants to be freed—itself an offshoot of the earlier
claim, “information wants to be free”27 —masks the labor expended in “freeing”
data, especially in cases where data, in the words of her research subjects, are
“stuck” or “disloyal.”
Cornelius Puschmann and Jean Burgess describe two predominating groups of
20 Rob Kitchin, “Big Data, New Epistemologies and Paradigm Shifts,” Big Data & Society 1, no. 1
(April 2014): 205395171452848-12, doi:10.1177/2053951714528481.
21 Mark Nunes, “Baudrillard in Cyberspace: Internet, Virtuality, and Postmodernity,” Style 29
(1995): 314-27; Sally Wyatt, “Danger! Metaphors at Work in Economics, Geophysiology, and
the Internet,” Science, Technology, & Human Values 29, no. 2 (August 18, 2016): 242-61,
doi:10.1177/0162243903261947; Rowan Wilken, “An Exploratory Comparative Analysis of the Use
of Metaphors in Writing on the Internet and Mobile Phones,” Social Semiotics 23, no. 5 (November
2013): 632-47, https://towardsdatascience.com/big-data-metaphors-we-live-by-98d3fa44ebf8.
22 as Teun A. van Dijk,“Principles of Critical Discourse Analysis,” Discourse & Society4, no. 2
(1993): 249-83; “Critical Discourse Analysis,” in The Handbook of Discourse Analysis, (West Sussex,
UK: Wiley, 2015), 466-85.
23 van Dijk, “Critical Discourse Analysis,” 473.
24 Rowan Wilken, “An Exploratory Comparative Analysis of the Use of Metaphors in Writing on the Internet and Mobile Phones,”Social Semiotics 23, no. 5 (November 2013): 632-47,
doi:10.1080/10350330.2012.738999.
25 Wilken,“An Exploratory Comparative Analysis,” 642.
26 Dawn Nafus,“Stuck Data, Dead Data, and Disloyal Data: the Stops and Starts in Making Numbers Into Social Practices,” Distinktion: Journal of Social Theory 15, no. 2 (June 17, 2014): 208-22,
doi:10.1080/1600910X.2014.920266.
27 Stewart Brand, The Media Lab, (New York: Viking Penguin, 1987), 202.

5

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

metaphors around contemporary descriptions of data:1) data as a natural force
to be controlled and 2) data as a resource to be consumed.28 As a resource, the authors note data are analogized to “food and fuel,” staple materials which “must be
consumed to exist and to move forward rather than being consciously used.”29 As
a force of nature, the authors observe data are often described as being in a liquid state: “allusion to water [or oil]” they write, “supports the notion that data
is all at once essential, valuable, difficult to control, and ubiquitous.”30 From data
lakes, rivers, and oceans to data floods, deluges, and tsunamis, these metaphors
position data as something massive and volatile while also necessary to support
human life.31 As Deborah Lupton notes, however, liquid metaphors also tacitly
work to forestall ethical or regulatory interventions by positioning data as ubiquitous, uncontrollable, and resistant to transparency or accountability.32
Both discursive strains—data as force and resource—point toward additional
metaphors rooted in industrial production. As Sara M. Watson observes, many
of our metaphors for data in the “knowledge economy” reference older industrial occupations.33 Efforts to think through or propose strategies for managing
data, in particular, rely on appeals to industrial imagery.34 Descriptions of data as
“toxic” or “radioactive” evoke images of massive nuclear facilities and radioactive
waste management experts.35
Curiously, as Tim Hwang and Karen Levy point out, often “people are nowhere
to be found” in this landscape of data metaphors:36 the excess of environmental
28 Cornelius Puschmann and Jean Burgess, “Big Data, Big Questions| Metaphors of Big Data,” International Journal of Communication 8 (2014).
29 Puschmann and Burgess, “Big Data, Big Questions,” 1700.
30 Puschmann and Burgess, “Big Data, Big Questions,” 1699.
31 The now-ubiquitous metaphor of “cloud” computing has similar resonances, though it captures
data as vaporous—somewhere between an invisible gas and a suffocating liquid.
32 Deborah Lupton, ”Swimming or Drowning in the Data Ocean? Thoughts on the Metaphors of
Big Data,” The Sociological Life, October 29, 2013.
33 Sara M. Watson, “Metaphors of Big Data,” DIS Magazine, May 28, 2016.
34 Kailash Awati and Simon Buckingham Shum, ”Big Data Metaphors We Live by,” Towards Data
Science, May 14, 2015.
35 Cory Doctorow, ”Why Personal Data Is Like Nuclear Waste,” The Guardian, January 15,
2008.)Metaphors referencing more quotidian forms of waste also point toward the similarly quotidian forms of work involved in data science: are those who work with data “rock stars” or “data
janitors”—or both?((Lilly Irani, ”Justice for ‘Data Janitors’,” Public Books, January 15, 2015.
36 There is one notable—and noxious—analogy which does foreground people: “big data is like
teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone
else is doing it, so everyone claims they are doing it….” Posted to Facebook in 2013 by Dan Ariely,
Professor at Duke University, the phrase has since been popularized in numerous blog posts, news
articles, and talks. We have deliberately omitted this analogy, however, as we find it more problematic
than insightful. Specifically, we do not wish to contribute to the sexualization of technological work—
a process * often serves to exclude or marginalize women in STEM—or engage in the belittling of
young persons’ sexual development. While other work may find constructive connections between

6

Cultural Analytics

Data Is the New What?

metaphors for data “do us a disservice by masking the human behaviors, relationships, and communications that make up all that data we’re streaming and
mining.”37 By analogizing digital data as a part of the “natural world”—the latter
term itself a techno-scientific reification and justification of centuries of imperial and settler colonial exploitation38 —the status of data as a record of human
activity is doubly occluded.39

Method and Analysis
To explore the relationships between data science, data metaphors, and professional ethics, we undertook a comparative discourse analysis of two sets of textbased data: 1) the text of ethics codes conventionally accepted as relevant to data
science today and 2) the text of ethics codes from professions associated with
popular or dominant data metaphors. Codes for both sets were accessed through
the Center for the Study of Ethics in the Professions, which indexes more than
2500 codes and guidelines from over 1500 organizations, dating from 1887 to the
present.40 For our first set of codes, we drew from dominant professional associations in information and computing fields, namely the Association of Computing Machinery (ACM) and the Institute of Electrical and Electronics Engineers
(IEEE). We also identified major professional associations in the areas of mathematics and statistics, like the American Statistical Association. This set of codes
provide a baseline of historically salient professional and ethical concerns in domains which—at least on the surface—directly inform the development, training,
and backgrounds of today’s data scientists.41
For the second set, we selected codes that 1) spoke directly to our identified
metaphors/concepts and 2) were of sufficient length and substance to effectively
compare with the well-developed codes in our first set. For example, if data is often framed as a natural resource, then we considered professions engaged in the
sexual ethics and data ethics broadly (see, for example, work on the ethics of consent: Una Lee and
Dann Toliver, Building Consentful Tech, Toronto, ON: And Also Too, 2017.), we do not find this
particular analogy productive.
37 Hwang and Levy, “ ‘The Cloud’ and Other Dangerous Metaphors.”
38 Kavita Philip, “Nature, Culture Capital, Empire,” Capitalism Nature Socialism 18, no. 1 (March
2007): 5-12, doi:10.1080/10455750601164584.
39 Irina Raicu, ”Metaphors of Big Data,” Recode, February 26, 2016.
40 The CSEP’s Ethics Code Collection is available at http://ethicscodescollection.org. For further
information on the CSEP’s collection and update policy, please see http://ethics.iit.edu/ecodes/node/
5421.
41 Jeff Hammerbacher, “Information Platforms and the Rise of the Data Scientist,” in Beautiful Data:
the Stories Behind Elegant Data Solutions, ed. Toby Segaran and Jeff Hammerbacher, (Sebastopol, CA,
2009), 73-84.

7

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

extraction and stewardship of resources, as with forestry; if big data is considered
“radioactive,” then we looked to professionals tasked with the storage, management, and safekeeping of radioactive or toxic materials. Data collection was further informed by our own knowledge of terms and metaphors, derived from our
own experiences working with and educating data scientists (for example, commonly employed terms like “cleaning,”— i.e. processing—data) and studying the
ethics and rhetoric of data-intensive platforms more broadly.42 We also drew on
discussions of predictive analytics equating practices of data-driven forecasting
and prediction with the work of astrologers.43 Finally, inspired by descriptions of
online data as the material traces humans leave behind (akin to, say, dead skin
cells), we drew on the ethics of funeral directors and morticians charged with
overseeing and caring for human remains.
In total, we selected 20 ethics codes for analysis. These codes ranged in length
from approximately 330 to 4300 words, with a mean length of approximately 1300
words and a median length of approximately 800 words. Many of the codes were
undated, with those with dates ranging from 1992 to 2016 (see Appendix A for
details). We used the qualitative research software ATLAS.ti to aid in manual
qualitative coding of the corpus according to principles of critical discourse analysis (CDA).44 We focused, in particular, on CDA’s commitment to mark both
the social actorsand social actionsexplicit and implicit in a given text.45 As professional codes aim to regulate (to varying degrees) the practice of professionals in
a given domain, we were interested first in identifying those actors (individual or
institutional) and actions (encouraged or prohibited) conceived of as relevant by
a given code. In addition, we also identified and labeled references to any explicit
value or virtue (i.e., “fairness,” “honesty,” “integrity”), allowing us to connect specific values to specific actors or practices. As such, our analysis was “directed,”
as our coding scheme was derived both before (the actor/action frame adopted
prior to coding) and during (values identified while coding) the analysis.46
42 Oliver L. Haimson and Anna Lauren Hoffmann, “Constructing and Enforcing ‘Authentic’ Identity Online: Facebook, Real Names, and Non-Normative Identities,” First Monday 21, no. 6 (June
6, 2016), doi: http://dx.doi.org/10.5210/fm.v21i6.6791; Anna Lauren Hoffmann, Nicholas Proferes,
and Michael Zimmer, “ ‘Making the World More Open and Connected’: Mark Zuckerberg and the
Discursive Construction of Facebook and Its Users,” New Media & Society 12, no. 1 (January 13,
2017): 146144481666078-20, doi:10.1177/1461444816660784.
43 Maude Standish, ”Data Is the New Astrology,” The Huffington Post, April 25, 2013; Kate Crawford, “Asking the Oracle,” in Laura Poitras: Astro Noise, (New York/New Haven, CT, 2016), 138-53.
44 Theo van Leeuwen, Discourse and Practice: New Tools for Critical Discourse Analysis (Oxford
Studies in Sociolinguistics), Oxford: Oxford University Press, 2008.
45 van Dijk, “Critical Discourse Analysis,” 466.
46 H. F. Hsieh, “Three Approaches to Qualitative Content Analysis,” Qualitative Health Research 15,
no. 9 (November 1, 2005): 1277-88, doi:10.1177/1049732305276687.

8

Cultural Analytics

Data Is the New What?

Analysis
Despite the broad range of sampled fields and subject areas, ethics codes in the
corpus demonstrated considerable thematic overlap. Much of this overlap is a
matter of genre—ethics codes are recognizable as such precisely because they
share certain schematic and substantive markers.47 For example, prohibitions on
maintaining conflicts of interest were common across all codes, regardless of professional domain. In the following, we focus less on thematic overlap and instead
on social actorsand social actions explicit or implicit within the codes, noting 1)
where the codes from different domains diverge and 2) and how each relates to
representative virtues or other forms of ethical behavior.

Social Actors
Professional ethics codes often position the individual practitioner as the primary
locus of ethical responsibility.48 Individuals are asked to take the brunt of ethical
conflict and adjudicate between potentially conflicting or incommensurate values.49 The codes we examined followed this pattern, foregrounding the individual practitioner as a primary social actor through an emphasis on personal responsibility. Only rarely were codes extended to cover responsibilities of others,
especially those above, around, or below an individual professional. References
to individual professional competence also appear frequently across both sets of
codes: individual professionals are directed to take on work or perform tasks only
within their specific domain (or sub-domain) of expertise, and to not falsify or
misrepresent their credentials.
What did vary, however, was the scope and range of social actors considered
relevant to a professional context. The absence of considerations for third parties in most of the codes was notable, especially for professions where a code’s
stated professional ethical commitments could easily conflict with—or had evident impacts on—third parties. While a number of the sampled codes state
commitments both to the general public and to the interests of the employer or
47 Gaumnitz

and Lere, “A Classification Scheme for Codes of Business Ethics.”
“Professional Ethics.”
49 Ethics codes thus perform for professionals in the abstract what the interaction design of many
digital platforms does for gig workers in practice: figure their subjects as “moral liability sponges”
or “moral crumple zones.” See Alex Rosenblat and Luke Stark, “Algorithmic Labor and Information
Asymmetries: a Case Study of Uber’s Drivers,” The International Journal of Communication 10 (July
27, 2016): 3758-84; and M. C. Elish, “Moral Crumple Zones: Cautionary Tales in Human-Robot
Interaction” (We Robot 2016) (March 20, 2016). We Robot 2016 Working Paper. Available at SSRN:
https://ssrn.com/abstract=2757236 or http://dx.doi.org/10.2139/ssrn.2757236
48 Abbot,

9

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

profession more narrowly, the morality of a profession’s or an employer’s motives are not scrutinized, and the individual has no guidance on how to navigate
moral conflicts. One exception was the Association of Computer Machinery’s
ethics code, which contained explicit provisions around whistleblowing—likely
inspired by the historical relationship between computing, state and corporate
surveillance, and privacy harms.50
Other actors—sometimes people, other times objects, spaces, or ideals—are
evoked across these codes through what we refer to as “responsibility to”
language. At any given time, an individual professional may have (per their
relevant code) a responsibility to: specific other actors (clients, colleagues, users,
employees, or employers); general others (the public, society, or simply “others”); a political body (nation, country); specific objects or ideals (technology,
truth, knowledge, the profession); or abstract spaces or sites (nature). The
particular discursive arrangement of these other actors hints at a given code’s
imagined scope. Those addressing only interpersonal or work relationships with
colleagues, employers, or employees could be understood as relatively narrow
in scope, suggesting the body responsible for developing the code either 1) did
not imagine the profession as playing a broad social role or 2) wanted to actively
avoid offering moral guidance on issues beyond the immediate workplace.
Beyond colleagues and employer/employee relationships, some of the surveyed
codes cited specific responsibilities to users (presumably of a particular system
and not of technology generally). This focus was, unsurprisingly, a common
theme in computing and information codes, where broader ethical commitments
were often treated as high-level abstractions and more precise attention was paid
to intra-professional considerations. Accordingly, social issues and problems of
the public good were often reduced to their most technocratic features. For example, the Code of Ethics of the American Society for Information Society & Technology (ASIS&T) begins by urging “its members to be ever aware of the social,
economic, cultural, and political impacts of their actions or inaction,” yet proceeds to detail explicit responsibilities to employers, clients, and system users—
and not society more broadly.
Other information and computing codes also evoked such “general others”
briefly. The IEEE Code of Ethics merely implores professionals “to accept
responsibility in making decisions consistent with the safety, health, and welfare
50 David Lyon, ed., Surveillance as Social Sorting: Privacy, Risk and Digital Discrimination, (New
York: Routledge, 2003); Herman Tavani, “Privacy Enhancing Technologies as a Panacea for Online
Privacy Concerns: Some Ethical Considerations,” Journal of Information Ethics 9, no. 2 (2000); Helen
Nissenbaum, “Respecting Context to Protect Privacy: Why Meaning Matters,” Science and Engineering Ethics 109, no. 4 (July 11, 2015): 1-22, doi:10.1007/s11948-015-9674-9.

10

Cultural Analytics

Data Is the New What?

of the public, and to disclose promptly factors that might endanger the public
or the environment.” The Association of Computing Machinery (ACM) was
again an exception, with its code going into detail regarding “general moral
imperatives” and their specific features. For example, the broad stated obligation
to “contribute to society and human well-being” is followed by the somewhat
more precise imperative to “protect fundamental human rights” and “respect
the diversity of all cultures.” While still vague, this explication does offer some
insight into how the ACM conceives of “human well-being.”
In contrast to information and computing codes, codes related to statistics
and statistical work consistently foregrounded professional responsibilities to
the public or society. The Statistical Society of Canada lists responsibilities to
society first while the Royal Statistical Society (UK) singles out “an overriding
responsibility to the public good.” The American Statistical Association (ASA)
goes the furthest in making statisticians’ responsibility towards society explicit,
averring that “the discipline of statistics links the capacity to observe with
the ability to gather evidence and make decisions, providing a foundation for
building a more informed society.” The ASA also details a set of commitments
aiming to limit or reduce the chance an individual practitioner will be placed
in a morally tenuous position by a third party, for example by “[striving] to
protect the professional freedom and responsibility of statistical practitioners,”
especially in cases where “analyses…are known or anticipated to have tangible
physical, financial, or psychological impacts.” Further, it asks employers to
“recognize that the results of valid statistical studies cannot be guaranteed to
conform to the expectations or desires of those commissioning the study or the
statistical practitioner(s).” While the ASA code does not stipulate further ethical
commitments the employer may have, it does to some degree acknowledge
and incorporate the how statistical work interacts with corporate or other
institutional processes.
In addition, these statistics-based ethics codes incorporate ethical concerns from
the broader history and trajectory of research ethics. The ASA code specifically
details an obligation to seek consent, especially for secondary or indirect uses of
data. It also gestures towards concerns of justice in research ethics, noting, “statistical descriptions of groups may carry risks of stereotypes and stigmatization.”
In response, “statisticians should contemplate, and be sensitive to, the manner in
which information is framed so as to avoid disproportionate harms to vulnerable
groups.” Given these codes are intended to inform statisticians’ research practices, it is perhaps unsurprising the treatment of research subjects would feature
prominently as objects of ethical concern - but makes it all the more notable that
data scientists, who as Beaton notes share a lineage with both statisticians and
11

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

psychologists, have yet to fully embrace such language.51
Codes associated with data metaphors often suggested responsibility to broadly
construed spaces, sites, or ideals through the language of stewardship. For
instance, the Society of American Foresters defines the forestry profession as
“[serving] society by fostering stewardship of the world’s forests,” while the
North American Nature Photography Association articulates its ethics through
principles of stewardship of and non-interference with various natural habitats.
Professions charged with sanitation, cleanliness, or dealing with hazardous
waste also address environmental concerns. For Certified Hazardous Materials
Managers, the “primary responsibility is to protect the public and the environment.” For the International Sanitary Supply Association (ISSA), public health
is paramount—all commercial considerations are, according to their code of
ethics, secondary to this broader concern.
In contrast to stewardship-based or environmental models, which tend to refer to
objects in the material world, computing and statistics codes tend to foreground
a specific value or ideal and then work to situate professional ethical responsibilities in service of this higher ideal. In statistics codes, for example, “truth” and
“objective knowledge” emerge as both quasi-deontological ends-in-themselves
and contested categories professionals must strive to realize in their work. Section A of the American Statistical Association specifically addresses statisticians’
obligations to reduce, mitigate against, or eliminate biases—either on the part
of the professional or the contracting party—which might skew research results.
An ethical statistician, the Code asserts, “uses methodology and data that are
relevant and appropriate, without favoritism or prejudice, and in a manner intended to produce valid, interpretable, and reproducible results.” The unethical
statistician, then, is one who manipulates data or skews findings in ways that are
self-serving or aims to deliberately mislead or manipulate others.
Finally, there was also variation in the codes with regard to the positioning of
ethics relative to a given professional. In a few cases, ethics was construed not as
a set of commitments, but as constitutive of professional identity. For example,
the code of ethics for the Association of Information Technology Professionals
(AITP) states the standards set out by the code “are not objectives to be strived
for, they are rules that no true professional will violate.” Though seemingly minor, this difference has consequences for professional identity and regulation:
ethics as professional commitment implies one can remain a “professional” even
when acting in ways potentially construed as unethical, while, conversely, ethics
51 Brian Beaton, “How to Respond to Data Science: Early Data Criticism by Lionel Trilling,” Information & Culture: a Journal of History 51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303.

12

Cultural Analytics

Data Is the New What?

as constitutive of professional identity implies that a breach of ethics simultaneously disqualifies one’s status as a professional.

Values and Social Actions
Where the previous section focused on actors and objects, this section focuses on
specific values and actions captured or implied in the surveyed ethics codes. Not
only do ethics codes represent an effort to define and delimit an ideal ethical professional, they also work to articulate, set, and scope out the sorts of actions and
values endemic to a particular profession. These actions often perform justificatory work (e.g., positioning certain actions as socially useful helps justify a profession’s existence) or work to stave off certain types of attention (e.g., clearly stated
prohibitions on certain actions may help deflect public or regulatory scrutiny).
Additionally, stated values reveal something about the anticipated impact of a
given action—positioning something as potentially discriminatory, for example,
demonstrates an awareness of a profession’s political impact. In this way, references to specific values or virtues offer insight into the ethical tenor of actions an
individual might be expected to undertake or account for in their capacity as a
professional.
Within the inventory of values laid out in the codes we analyzed, some of the
starkest divisions came between computing and statistics codes, and those codes
associated with data metaphors. A dominant theme across all analyzed codes was
a proscription against what we term “biopolitical harms”: environmental harms,
and the health and safety of populations.52 This emphasis suggests a parallel to the
preponderance of resource-based metaphors for data—namely a sense that, in the
abstract, it is easy for professionals to agree to protecting (or perhaps, managing)
the natural world and natural resources, as part of what Gabriel Abend terms “the
moral background” to professionalism itself.53 In contrast, computing codes and
statistics codes often foreground political issues of privacy and freedom of speech,
as well as conceptions of data as confidential and requiring safeguarding. This
attention to privacy, security, and speech grows out of a longer-standing focus on
these areas during the development of information technology and computing
52 Patricia Ticineto Clough and Craig Willse, “Gendered Security/National Security: Political
Branding and Population Racism,” March 7, 2013; Michel Foucault Collège de France, The Birth of
Biopolitics: Lectures at the Collège De France, 1978-1979, 1st ed., (New York: Picador, 2010); Matthew
B Sparke, “A Neoliberal Nexus: Economy, Security and the Biopolitics of Citizenship on the Border,”
Political Geography no. 25, no. 25 (2006): 151-80, doi:10.1016/j.polgeo.2005.10.002.
53 Gabriel Abend, The Moral Background (Princeton, NJ and Oxford: Princeton University Press,
2014).

13

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

ethics.54 Save for limited references to confidentiality in the codes of The Wildlife
Society and Society of American Foresters, privacy and speech considerations are
absent in our second set of codes.
Given established historical connections between information technology,
communication, and privacy, the emphasis on the latter in computer science
codes makes sense. However, it also points to one of the starkest differences
between the conventional codes and those codes rooted in our data metaphors:
the former tends to foreground abstract users, rights, and values, while many
of the metaphor-based codes explicitly revolve around material stewardship,
public health, and bodily safety. For example, the Code of Ethics for Hazardous
Materials Managers explicitly states that professionals’ “primary responsibility
is to protect the public and the environment,” while “the interests of individual
clients and employers must be secondary.” In a different way, the code of ethics
for The Wildlife Society places “research and scientific management of wildlife
species, their environments, and stakeholders” as primary and specifically
directs professionals to educate broadly construed others on these topics. This
contrast between abstract values in the conventional codes and material stewardship in the metaphor-based codes lends support to the idea that conventional
codes’ outsized focus on issues like privacy and speech—themselves heavily
informed by the technical rather than social affordances of computers—has
limited their ability to account for a wider range of potential social, political,
and environmental harms.55 A focus on natural resources as a site for both
conservation and potential harm also helps professionals avoid the social
complexities and challenges of adjudicating their responsibilities to society as
comprised of other people, instead of a material background.
Finally, a number of the sampled codes formally prohibit discrimination, and
some others contain explicit lists of those classes of people deserving of particular
protection. However, only the code of ethics for the National Funeral Directors
Association made an explicit connection between the mission of the profession
54 Tavani, “The State of Computer Ethics as a Philosophical Field of Inquiry;” Frances S. Grodzinsky and Herman T. Tavani, “Applying the ‘Contextual Integrity’ Model of Privacy to Personal Blogs
in the Blogosphere,” International Journal of Internet Research Ethics 3 (December 30, 2010): 38-47;
Lucas D. Introna, “Maintaining the Reversibility of Foldings: Making the Ethics (Politics) of Information Technology Visible,” Ethics and Information Technology 9, no. 1 (December 21, 2006): 11-25,
doi:10.1007/s10676-006-9133-z.
55 Literature on the concept of “securitization” supports this view: when topics of public debate
are securitized, they are removed from the realm of political contestation and deemed to be technical
matters addressable by experts. See Lene Hansen and Helen Nissenbaum, “Digital Disaster, Cyber
Security, and the Copenhagen School,” International Studies Quarterly 53 (2009): 1155-75; Helen Nissenbaum, “Where Computer Security Meets National Security,” Ethics and Information Technology 7
(2005): 61-73, doi:10.1007/s10676-005-4582-3.

14

Cultural Analytics

Data Is the New What?

and a specific vulnerable class of people.56 Specifically, people of low socioeconomic standing or limited financial means are cited as deserving particular consideration in view of funeral directors’ mission to “to provide families with meaningful end-of-life services at the highest levels of excellence and integrity.”57 This
commitment is explicitly accounted for in a prohibition against withholding services (like delaying the embalming process) or the body of a loved one (from
release to a family or other legally recognized party) until payment for services
has been received. While clearly rooted in a concern over extortionate business
practices and hucksterism—as well as the time sensitive nature of some features
of morticians’ work—there is, perhaps a lesson for data scientists here in how to
think about specific power dynamics at play. For example, a code of ethics for
data scientists might be careful to not make certain kinds of data or informational
transparency contingent on an ability to pay or by coercing users to give up more
personal data in the process.

Discussion & Recommendations
Our analyses of professional ethics codes from both computer science and from
metaphorically related fields suggest several broad conclusions relevant to conversations about data in the public sphere, and to data science as an emerging
profession.
First, one of the chief values common to codes from across our sample was fairness. In the context of computer science ethics, fairness is a hot topic: computer
scientists interested in fairness, accountability, transparency and other values in
machine learning and artificial intelligence have already begun to interrogate
how fairness might be translated into computational metrics for evaluating algorithms and systems.58 A parallel movement in science and technology studies
and information science has focused on the need to articulate fairness not only
as an allocative metric internal to digital systems, but also as social one addressing systematic discrimination, bias, and representational harms.59 In the context
56 It is worth noting that The Wildlife Society does address unspecified “stakeholders” in the wellbeing of certain wildlife species. These stakeholders could easily include oppressed individuals or
groups deserving of particular consideration, especially native or indigenous peoples. However, these
groups are not specifically named in the code.
57 ”About NFDA,” National Funeral Directors Association, June 9, 2018.
58 Solon Barocas and Andrew D. Selbst, “Big Data’s Disparate Impact,” California Law Review 104
(2016): 671-732. doi:10.15779/Z38BG31; Chelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito,
and Jonathan Zittrain, “Interventions Over Predictions - Reframing the Ethical Debate for Actuarial
Risk Assessment,” Proceedings of Machine Learning Research 81:1-15, 2018.
59 Anna Lauren Hoffmann, “Data Violence and How Bad Engineering Choices Can Damage Soci-

15

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

of professional ethics codes, however, fairness takes on yet another meaning: as
a sign of interpersonal trust within a profession, and a signal for professional
frankness and honesty.
The strong emphasis on fairness within the conventional codes we sampled may
in fact be connected to the technical definitions of fairness increasingly prominent in computer science literature: technical systems are perceived by computer
scientists and data scientists as objects which are the fruit of expert processes of
collaboration and communication, and so those same expert processes would, in
theory, be able to similarly produce technical definitions of values—such as fairness. The strong emphasis on computational solutions to values questions has
much to do with common areas of professional familiarity, expertise and technical language among participants. Fairness is a complicated concept in noncomputational contexts as well as computational ones. We argue, however, a
reemphasis on fairness as a social value (in line with honesty, frankness, and
“good faith”) would help reorient data science and related professions towards
their broader social role.
The professional codes we sampled—from CS and from other fields—are also
highly focused on technical and professional credibility. This second insight is
related to our first point above: professional fairness and honesty are integral to
technical credibility and recognition of expertise. However, scholarly work in
the sociology of trust that observes trust as a social construct is only partially
focused on technical credibility, or whether a person or institution is able to perform the task they claim they will do.60 While the voluminous literature on trust is
too broad to more than briefly sample here, the other key aspect of social trust is
benevolence: the notion that a trusted person or organization has the best interests of the trustor at heart.61 The emphasis across professional codes for computer
science is credibility, and less so benevolence.
Given an increasing scholarly and public awareness of the social impacts of big
data, ML, and AI, the lack of attention to social benevolence in the conventional
ety,” Medium (Member Feature Story), 30 April 2018, available at https://medium.com/s/story/dataviolence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4
60 Linda D. Molm, Nobuyuki Takahashi, and Gretchen Peterson, “Risk and Trust in Social Exchange: an Experimental Test of a Classical Proposition,” The American Journal of Sociology 105,
no. 5 (March 2000): 1396-1427; Susan P. Shapiro, “The Social Control of Impersonal Trust,” American Journal of Sociology 93, no. 3 (November 1987): 623-58; Guido Möllering, “The Trust/Control
Duality,” International Sociology 20, no. 3 (June 29, 2016): 283-305, doi:10.1177/0268580905055478.
61 Matthew K. O. Lee and Efraim Turban, “A Trust Model for Consumer Internet Shopping,” International Journal of Electronic Commerce 6, no. 1 (October 1, 2001): 75-91,
doi:10.2307/27751003?ref=search-gateway:65426dfa915042907ae6237cf88297e1; David Gefen, Izak
Benbasat, and Paula Pavlou, “A Research Agenda for Trust in Online Environments,” Journal of Management Information Systems 24, no. 4 (May 12, 2008): 275-86, doi:10.2753/MIS0742-1222240411.

16

Cultural Analytics

Data Is the New What?

codes is notable and in need of remedy. Here, insights rooted in our data
metaphors stand to be of particular use. For certain professions concerned with,
for example, sanitation or the handling of hazardous materials, benevolence
(often in the form public or environmental safety) is paramount—it works
as an overarching frame for judgments of professional duty and competence.
Accordingly, we should ask critical questions about how broadly or narrowly
“competence” in particular data scientific projects should be construed. For
example, while a data scientist might have expertise in particular computational
and statistical methods, they may know very little—in the social scientific
sense—about the particular communities or behaviors captured in a given
dataset. Interpreting competence in view of social benevolence would require
some knowledge of particular communities, behaviors, or broader social and
political forces (or at least a requirement to contract or seek out collaborations
with other professionals or community members who do possess such expertise). In certain contexts, it may even be useful to follow the lead of morticians
and funeral directors in codifying historically-salient social or political groups
deserving of particular consideration. Though not represented in our surveyed
codes, the activist slogan “nothing about us without us” (notably espoused
by disability activists in the United States) may be a useful starting point for
reasoning about data scientists’ social obligations.62
In addition, ethical commitments addressing both the employer and the employed, as well as possible conflicts between those ethical commitments, are particularly relevant for thinking through the ethics of data science within large corporate settings. Economic incentives and ethical commitments to the privacy,
security and labor rights of both data subjects and employees often come into
conflict63 —for example, when data or scientific work might contribute to the development of military weapons and targeting systems. How to harmonize broad
social commitments with both individual professional practice and corporate
structures in the data science context—especially since, given the heavy reliance
on gig or crowd labor in data science, it remains an open question just who the
individual professional figured across the codes we surveyed might be—is a necessary subject for further research and activism.64 Related conversations around
the ethics and governance of AI provide an instructive parallel case.65 Data gov62 James I. Charlton, Nothing About Us Without Us: Disability Oppression and Empowerment,
(Berkeley and Los Angeles: University of California Press, 1998).
63 Noëmi Manders-Huits and Michael Zimmer, “Values and Pragmatic Action: The Challenges of
Introducing Ethical Intelligence in Technical Design Communities,” International Review of Information Ethics, January 30, 2009, 1-8.
64 Kate Conger, ”Google Plans Not to Renew Its Contract for Project Maven, a Controversial Pentagon Drone AI Imaging Program,” Gizmodo, June 1, 2018.
65 Daniel Greene, Anna Lauren Hoffmann, and Luke Stark, “Better, Nicer, Clearer, Fairer: A Crit-

17

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

ernance through the lens of human rights is one possible approach in this vein,
though the suitability and effectiveness of human rights discourse in mobilizing
good corporate governance and change for social justice is an open question.66
A related insight drawn from our analysis concerns the notion of the fiduciary,
and their “fiduciary duty.” A fiduciary is a trustee, and a fiduciary duty is the legal
obligation of one party to act in the best interest of another. Doctors and lawyers,
for instance, have fiduciary duties to their patients and clients—so do other professionals such wealth managers and morticians. Legal scholars Jack Balkin and
Jonathan Zittrain have recently developed the concept of the “information fiduciary,”67 entailing data scientists and the companies they work for—like Facebook
and Google—accepting “the duty to use personal data in ways that don’t betray
end users and harm them.”68
We see several points from our analysis pertaining to the information fiduciary
model. One is that for the most part, professions with fiduciary duties protect
personal data as a secondary result of their primary duty of care: to the health of
a patient, to (in theory) the law and justice, to the bodies of the dead. For example,
doctors and morticians, more so than lawyers, are intimately engaged in caring
for us as embodied agents. Standards for trusting doctors and morticians are
thus high: we imagine a doctor, on the average, to be honest—both credible and
benevolent—in a way we may not (alas) imagine a computer scientist.
Data scientists and their employers are generally presented as being in the business of collecting and analyzing data as a primary goal—but this is of course an erroneous view. Data scientists and computer programmers invariably work in and
across various domains and their work has, in many cases, obvious material consequences—from precision medicine to criminal sentencing.Here, the emphasis
on material stewardship found in metaphor-based codes of ethics, as opposed to
the valorization of abstract ideals found in many computer science codes, shows
how the material objects of a profession’s attention can be obscured by a profession’s conceptual axioms. Data scientists as a profession are generally associated
with abstraction and disembodiment, with numbers aggregated and immaterial
ical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning,” Hawaii
International Conference on System Sciences (HICSS 2019), Maui, HI.
66 Mark Latonero, Governing Artificial Intelligence: Upholding Human Rights and Dignity, Data &
Society Research Institute, (10 October 2018), available at https://datasociety.net/output/governingartificial-intelligence/; Ron Dudai, “Human Rights in the Populist Era: Mourn then (Re)Organize,”
Journal of Human Rights Practice 9, no. 1 (February 2017): 16-21. https://doi.org/10.1093/jhuman/
hux005
67 Jack M. Balkin, “Information Fiduciaries and the First Amendment,” UC Davis Law Review 49,
no. 4 (April 2016): 1183-1234.
68 Jack M. Balkin and Jonathan Zittrain, ”A Grand Bargain to Make Tech Companies Trustworthy,”
The Atlantic, October 3, 2016.

18

Cultural Analytics

Data Is the New What?

in “the cloud.” Yet the real-world consequences on individual embodied humans
of data science can be real, visceral, and devastating. Likewise, discourses of data
as a force, a resource, and as an industrial product erase the human subjects both
of digital data collection and accumulation and its effects; yet they also lack the
traditions of stewardship and responsibility, which however imperfectly typify
the professional discourses in those fields.
Analogizing digital data as “natural” without stewardship discourses implicitly
signals data - and the living people it involves - are open for rank exploitation.
As Arvind Narayanan argues, “it’s not enough to ask if code executes correctly.
We also need to ask if it makes society better or worse.”69 The seeming abstraction of data is in some ways belied by the material metaphors used to describe
it: water, oil, and ore. Yet as Hwang and Levy note, these metaphors, though
material, deflect attention from the fact human data are produced and have impacts on human beings. We heartily concur with Rebecca Lemov: “ ‘Big data is
people’!”70 As such, we argue data scientists should be held to fiduciary standards
closer to those of doctors, morticians, or even hazardous waste managers—they
are professionals dealing with the human bodies and populations in ways that
demand a high degree of both credibility and benevolence. Professional ethics
in data science should include broader, more ecological thinking about the role
of data, computing, and statistical analyses in their social context and real-world
applications.
One final area where professional ethics codes related to data metaphors differed
from those in computer science was around the question of professional sanction.
For instance, the ethical code of the International Society of Petroleum Engineers
has an explicit clause encouraging practical mitigating action, and also states in
the code itself the mechanism through which members can report violations to
the professional body. If data is indeed the new oil, the IEEE and other data
science codes should be at least as explicit as that of petroleum engineers in listing
consequences for violations of the code and articulating how those violations can
be reported.
As noted above, there is one professional group thematically related to data science whose professional ethics codes demonstrate a relatively high degree of sensitivity to a variety of actors, societal values and broad-based social responsibility:
statisticians. Given the centrality of statistical analysis to data science, we suggest data scientists could do much worse than having a full-throated professional
engagement with statistical codes of conduct, and with the legacy of statistics
69 Doug Hulette, ”Patrolling the Intersection of Computers and People,” Princeton University Computer Science, October 2, 2017.
70 Rebecca Lemov, ”‘Big data is people!’” Aeon Magazine, June 16, 2016.

19

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

as a tool in social science research. Like data scientists, statisticians work with
many other professions, but nonetheless have articulated their social obligations.
Future scholarship engaging statisticians around the concept of “fiduciary duty”
would be valuable—a statistical fiduciary duty of care is one conceptual way to
understand the professional duties of data scientists and others engaging in data
analysis.

Conclusion
Our analytic goals in juxtaposing ethics codes in computer science and related
fields alongside codes related to data science metaphors are threefold. As scholars
working at the intersection of information science, science and technology studies (STS), and the philosophy and ethics of technology, we have an intellectual interest in tracing the conceptual connections and sociological themes of computer
and data science, the professions which to a large degree shape the technologies
and social practices around them which we study. Ethics codes are a micro-level
instantiation of broader structural and institutional values and debates. These
codes represent “the transformation of social practices into discourses about social practices”;71 they are not absolute or perfect representations of these discussions but sites where certain results of certain political, professional, and material
struggles are stabilized and put to work in the world.
However, we are also concerned with two other, practical normative outcomes: a
statement of the kinds of ethos we as critical scholars want to see permeate these
emerging data cultures; and a concomitant sense of how data scientists might
consider changing existing or nascent professional ethics codes in data science
in light of our findings and our broader normative commitments.
While many of our proposals are spelled out in the Discussion section above,
we make two more general recommendations for data scientists and those interested in professional ethics for data science. The first recommendation is to take
“ethics” as a starting point, not as an end. Codes of ethics increasingly serve to
demarcate data culture as a domain of experts, and conversations around professional ethics in data science and related fields such as ML/AI are a necessary
but absolutely insufficient condition for the kinds of progressive, just and equitable social outcomes we seek for the world. Testifying before the US Congress
in 2003 about another new and disruptive technical field, nanotechnology, STS
scholar Langdon Winner noted a historical tendency, as he saw it, “for those who
71 Theo van Leeuwen, Discourse and Practice: New Tools for Critical Discourse Analysis (Oxford
Studies in Sociolinguistics), Oxford: Oxford University Press, 2008, 105.

20

Cultural Analytics

Data Is the New What?

conduct research about the ethical dimensions of emerging technology to gravitate toward the more comfortable, even trivial questions involved, avoiding issues that might become a focus of conflict.”72 Digital technologies are powerful
tools: for data scientists to insufficiently engage with the rich social contexts and
disparate, sometimes conflicting human realities of their use is a lapse of a core
ethical obligation, courage, in itself. To limit conversations about the societal impacts and obligations of data science solely to professional ethics is a mistake we
are keen to have all parties involved avoid.
Our second recommendation concerns the relationship between professional
ethics codes in data science and data science pedagogy. The ethical norms of
a profession emerge out of every stage of that profession’s training process. As
such, we advocate forcefully for data science education to address not only the
professional ethics questions posed by extant professional codes, but also the
societal questions posed by the metaphors through which the profession, and
discourse more broadly, understands data. These metaphors can serve as what
Katie Shilton73 terms “values levers,” prompting novel conversations about data
science’s impacts and responsibilities to society at large. Innovative work on
broadening the terms of data science education is already underway.74 Data
science and data scientists would benefit from expanding their collaborations
with interdisciplinary work in STS, information studies, and media studies to
further reap the benefits of engaging with values, ethics, and norms at every
stage of their work.75
Finally, our ethical commitments as authors are grounded in a desire for data justice,76 design justice,77 as well as the recognition of historical injustices in emerging data cultures and in society more broadly. As Kate Crawford has put it, data
72 Langdon Winner, Testimony to the Committee on Science of the U.S. House of Representatives
on The Societal Implications of Nanotechnology, 9 April 2003, available at http://homepages.rpi.edu/
~winner/testimony.htm.
73 Katie Shilton,“Values Levers: Building Ethics Into Design,” Science, Technology, & Human Values 38, no. 3 (May 2013): 374-97, doi:10.1177/0162243912436985.
74 Michael Skirpan et al., “Ethics Education in Context,” (the 49th ACM Technical Symposium,
New York, New York, USA: ACM Press, 2018), 940-45, doi:10.1145/3159450.3159573; [Author,
2018]; Costanza-Chock, “Design Justice: Towards an Intersectional Feminist Framework for Design
Theory and Practice.”
75 Mary Flanagan and Helen Nissenbaum, Values at Play in Digital Games, (Cambridge, MA: The
MIT Press, 2014); Phoebe Sengers et al., “Reflective Design,” (Proceedings of the 4th Decennial
Aarhus Conference, Aarhus, Denmark, 2005), 49-58; Batya Friedman, Peter H. Kahn, and Alan Borning, “Value Sensitive Design and Information Systems,” in Human-Computer Interaction in Management Information Systems: Foundations, ed. B. Schneiderman, Ping Zhang, and D. Galletta, (New
York: M.E. Sharpe, Inc., 2006), 348-72.
76 Hoffmann, “Data Violence.”
77 Sasha Costanza-Chock, “Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice,” 2018, 1-14, doi:10.21606/dma.2017.679.

21

Luke Stark and Anna Lauren Hoffmann

Cultural Analytics

ethics needs to ask, “What kind of world do we want to live in?”78 We are explicit
about these normative commitments as a way to conceptually tax related ethics
codes and our data metaphors alike. With data-driven online platforms and digital systems already a potential source of bias and discrimination,79 the processual
ethics common to professional codes need to be supplanted by a more explicit
set of norms around data cultures as spaces for equality and justice—within and
beyond a code of ethics for data scientists.

Appendix: List of Professional Ethics Codes Consulted
Organization

Date Last Updated

Word Count

American Federation of Astrologers (AFA) Code of Ethics
American Mathematical Society Policy Statement on Ethical Guidelines
American Society for Photogrammetry and Remote Sensing Code of Ethics
American Statistical Association (ASA) Ethical Guidelines for Statistical Practice
Association for Computing Machinery (ACM) Code of Ethics and Professional Conduct
Association for Information Science and Technology (ASIS&T) Professional Guidelines
Association for Information Systems (AIS) Code of Research Conduct
Association of Information Technology Professionals (AITP) Code of Ethics & Standards of Conduct
Information Systems Security Association (ISSA) Code of Ethics
Institute for Certification of Computing Professionals (ICCP) Code of Ethics
Institute of Electrical and Electronics Engineers (IEEE) Code of Ethics
Institute of Hazardous Materials Management Code of Ethics and Professional Conduct
International Society of Petroleum Engineers Code of Ethics
National Funeral Directors Association Code of Professional Conduct
North American Nature Photography Association
Royal Statistical Society
Society of American Foresters Code of Ethics
Statistical Society of Canada Code of Ethical Statistical Practice
The Wildlfe Society Code of Ethics
The Worldwide Cleaning Industry Association
(ISSA) Member Code of Ethics

No date listed
2005
No date listed
2016
1992
1992
2013
No date listed
No date listed
No date listed
No date listed
No date listed
2013
2008
No date listed
No date listed
2000
No date listed
No date listed
2005

356
1729
658
3478
3459
531
4323
790
332
2145
429
895
561
1530
465
1718
833
766
1486
358

Unless otherwise specified, all work in this journal is licensed under a Creative
Commons Attribution 4.0 International License.

78 Kate Crawford, “AI Now: Social and Political Questions for Artificial Intelligence,” (University
of Washington, March 6, 2018), available at: https://www.youtube.com/watch?v=a2IT7gWBfaE.
79 Batya Friedman and Helen Nissenbaum, “Bias in Computer Systems,” ACM Transactions on Information Systems 14, no. 3 (September 5, 1996): 330-47; Joy Buolamwini and Timnit Gebru, “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,” Proceedings
of Machine Learning Research 81 (2018): 1-15.

22

